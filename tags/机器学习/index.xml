<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>机器学习 on LYon's Blog</title><link>https://yindongliang.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 机器学习 on LYon's Blog</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 23 Oct 2025 11:24:27 +0800</lastBuildDate><atom:link href="https://yindongliang.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>集体智慧编程</title><link>https://yindongliang.com/docs/Algorithms/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B/</link><pubDate>Mon, 18 Mar 2024 00:00:00 +0000</pubDate><guid>https://yindongliang.com/docs/Algorithms/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B/</guid><description>&lt;h2 id="第一章提供推荐">第一章：提供推荐&lt;a class="anchor" href="#%e7%ac%ac%e4%b8%80%e7%ab%a0%e6%8f%90%e4%be%9b%e6%8e%a8%e8%8d%90">#&lt;/a>&lt;/h2>
&lt;h3 id="欧几里得距离">欧几里得距离&lt;a class="anchor" href="#%e6%ac%a7%e5%87%a0%e9%87%8c%e5%be%97%e8%b7%9d%e7%a6%bb">#&lt;/a>&lt;/h3>
&lt;p>欧氏距离是平方和的开方，欧氏距离越小，则两个向量的相似度越大（有时也说距离越近）。&lt;/p>
&lt;p>$$d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$$&lt;/p>
&lt;p>对于两个 n 维向量 $\mathbf{A} = (a_1, a_2, &amp;hellip;, a_n)$ 和 $\mathbf{B} = (b_1, b_2, &amp;hellip;, b_n)$，它们之间的欧氏距离 $d$ 可以表示为：&lt;/p></description></item><item><title>周志华西瓜书</title><link>https://yindongliang.com/docs/Algorithms/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%91%A8%E5%BF%97%E5%8D%8E%E8%A5%BF%E7%93%9C%E4%B9%A6/</link><pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate><guid>https://yindongliang.com/docs/Algorithms/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%91%A8%E5%BF%97%E5%8D%8E%E8%A5%BF%E7%93%9C%E4%B9%A6/</guid><description>&lt;p>&lt;a href="https://www.bilibili.com/video/BV1gG411f7zX/?share_source=copy_web&amp;amp;vd_source=fe111319444213c0651c9b0de9740974">周志华老师亲讲-西瓜书《机器学习》&lt;/a>&lt;/p>
&lt;p>手推笔记&lt;br>
&lt;a href="https://github.com/Sophia-11/Machine-Learning-Notes">https://github.com/Sophia-11/Machine-Learning-Notes&lt;/a>&lt;/p>
&lt;h2 id="基础概念">基础概念&lt;a class="anchor" href="#%e5%9f%ba%e7%a1%80%e6%a6%82%e5%bf%b5">#&lt;/a>&lt;/h2>
&lt;p>&lt;strong>真相（Ground Truth）&lt;/strong>：在机器学习和数据科学中，&amp;ldquo;真相&amp;quot;指的是实际情况或数据的真实状态。这通常是指标准答案或一个已知的事实，用于训练和验证机器学习模型。例如，在图像识别任务中，标记图像中对象的正确标签就是&amp;quot;真相&amp;rdquo;。&lt;/p></description></item><item><title>BPE 子词分词算法</title><link>https://yindongliang.com/docs/LLM/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/BPE-%E5%AD%90%E8%AF%8D%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/</link><pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate><guid>https://yindongliang.com/docs/LLM/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/BPE-%E5%AD%90%E8%AF%8D%E5%88%86%E8%AF%8D%E7%AE%97%E6%B3%95/</guid><description>&lt;p>我们来详细介绍一下 &lt;a href="https://en.wikipedia.org/wiki/Byte-pair_encoding">&lt;strong>Byte-pair Encoding（BPE）&lt;/strong>&lt;/a>，这是一种在自然语言处理（NLP）领域非常流行且重要的子词分词算法。&lt;/p>
&lt;h3 id="1-核心思想解决什么问题的">1. 核心思想：解决什么问题的？&lt;a class="anchor" href="#1-%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3%e8%a7%a3%e5%86%b3%e4%bb%80%e4%b9%88%e9%97%ae%e9%a2%98%e7%9a%84">#&lt;/a>&lt;/h3>
&lt;p>在 NLP 任务中，我们需要将文本转换成模型能够理解的数字，即“分词”。传统方法主要有两种：&lt;/p></description></item><item><title>Embedding</title><link>https://yindongliang.com/docs/LLM/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/Embedding/</link><pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate><guid>https://yindongliang.com/docs/LLM/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/Embedding/</guid><description>&lt;p>好的，我们来深入探讨 &lt;strong>Embedding&lt;/strong>，这是现代 AI 尤其是 NLP 领域的核心基石。&lt;/p>
&lt;h3 id="第一部分embedding-详解">第一部分：Embedding 详解&lt;a class="anchor" href="#%e7%ac%ac%e4%b8%80%e9%83%a8%e5%88%86embedding-%e8%af%a6%e8%a7%a3">#&lt;/a>&lt;/h3>
&lt;h4 id="1-什么是-embedding">1. 什么是 Embedding？&lt;a class="anchor" href="#1-%e4%bb%80%e4%b9%88%e6%98%af-embedding">#&lt;/a>&lt;/h4>
&lt;p>&lt;strong>Embedding（嵌入）&lt;/strong> 是一种将高维、离散、稀疏的符号（如单词、产品、用户 ID）映射到低维、连续、稠密的向量空间中的技术。&lt;/p></description></item><item><title>OI Wiki</title><link>https://yindongliang.com/links/202510/oi-wiki/</link><pubDate>Wed, 22 Oct 2025 00:00:00 +0000</pubDate><guid>https://yindongliang.com/links/202510/oi-wiki/</guid><description>&lt;p>一个为编程竞赛准备的网站，主要涵盖算法与数学。&lt;/p></description></item><item><title>How I became a machine learning practitioner</title><link>https://yindongliang.com/links/202510/How-I-became-a-machine-learning-practitioner/</link><pubDate>Tue, 21 Oct 2025 00:00:00 +0000</pubDate><guid>https://yindongliang.com/links/202510/How-I-became-a-machine-learning-practitioner/</guid><description>&lt;p>OpenAI 共同創辦人 Greg Brockman《我如何成為機器學習實踐者》翻譯文&lt;br>
&lt;a href="https://www.explainthis.io/zh-hant/career/how-greg-turn-ml-practitioner">https://www.explainthis.io/zh-hant/career/how-greg-turn-ml-practitioner&lt;/a>&lt;/p></description></item></channel></rss>